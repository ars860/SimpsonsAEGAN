{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# from unet import Unet\n",
    "import torchvision as tv\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from enum import Enum\n",
    "\n",
    "\n",
    "# N_CLASSES = 11\n",
    "\n",
    "\n",
    "class SkipType(Enum):\n",
    "    SKIP = 0\n",
    "    NO_SKIP = 1\n",
    "    ZERO_SKIP = 2\n",
    "\n",
    "\n",
    "class UpBlock(nn.Module):\n",
    "    def __init__(self, ch_out, skip=SkipType.SKIP, dropout=None):\n",
    "        super(UpBlock, self).__init__()\n",
    "        self.skip = skip\n",
    "        self.upconv = nn.ConvTranspose2d(ch_out * 2, ch_out * 2, kernel_size=3, padding=1, stride=2, output_padding=1)\n",
    "        self.conv1 = nn.Conv2d(ch_out * 2 if skip == SkipType.NO_SKIP else ch_out * 3, ch_out, kernel_size=3, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(ch_out, ch_out, kernel_size=3, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "\n",
    "        if dropout is not None and dropout != 0:\n",
    "            self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, x, u=None, padding=None):\n",
    "        if u is None and self.skip:\n",
    "            raise ValueError(\"Expected skip connection\")\n",
    "\n",
    "        if padding is None:\n",
    "            padding = [x.shape[2] % 2, x.shape[3] % 2]\n",
    "\n",
    "        u = self.upconv(u)\n",
    "        u = F.pad(u, [padding[1], 0, padding[0], 0])\n",
    "\n",
    "        if self.skip == SkipType.SKIP:\n",
    "            x1 = torch.cat((x, u), dim=1)\n",
    "        elif self.skip == SkipType.ZERO_SKIP:\n",
    "            x1 = torch.cat((torch.zeros_like(x), u), dim=1)\n",
    "        else:\n",
    "            x1 = u\n",
    "\n",
    "        x2 = self.relu1(self.conv1(x1))\n",
    "        x3 = self.relu2(self.conv2(x2))\n",
    "        if getattr(self, 'dropout', None) is not None:\n",
    "            x3 = self.dropout(x3)\n",
    "        return x3\n",
    "\n",
    "\n",
    "class Unet(nn.Module):\n",
    "    def __init__(self, layers, output_channels=3, skip=SkipType.SKIP, dropout=None):\n",
    "        super(Unet, self).__init__()\n",
    "        prev_layer = 3\n",
    "        for i, layer in enumerate(layers, start=1):\n",
    "            setattr(self, f'down{i}', self.enc_block(prev_layer, layer, max_pool=prev_layer != 3))\n",
    "            prev_layer = layer\n",
    "        for i, layer in reversed(list(enumerate(layers[:-1], start=1))):\n",
    "            setattr(self, f'up{i}', UpBlock(layer, skip, dropout))\n",
    "        self.final = nn.Conv2d(layers[0], output_channels, kernel_size=1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward_vars(self, x):\n",
    "        children = list(self.named_children())\n",
    "        vars = {}\n",
    "        downs = list(map(lambda nm: nm[1], filter(lambda nm: 'down' in nm[0], children)))\n",
    "        ups = list(map(lambda nm: nm[1], filter(lambda nm: 'up' in nm[0], children)))\n",
    "        final = children[-2][1]\n",
    "        sigmoid = children[-1][1]\n",
    "\n",
    "        vars['x'] = x\n",
    "        for i, down_i in enumerate(downs[:-1], start=1):\n",
    "            vars[f'x{i}'] = down_i(vars[f'x{\"\" if i == 1 else i - 1}'])\n",
    "            print(\"down\", vars[f'x{i}'].shape)\n",
    "\n",
    "        vars[f'u{len(downs)}'] = downs[-1](vars[f'x{len(downs) - 1}'])\n",
    "        for i, up_i in enumerate(ups):\n",
    "            vars[f'u{len(ups) - i}'] = up_i(vars[f'x{len(ups) - i}'], vars[f'u{len(ups) - i + 1}'])\n",
    "            print(\"up\", vars[f'u{len(ups) - i}'].shape)\n",
    "\n",
    "        vars['res'] = final(vars['u1'])\n",
    "        vars['res_sigmoid'] = sigmoid(vars['res'])\n",
    "        return vars\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.forward_vars(x)['res_sigmoid']\n",
    "\n",
    "    def enc_block(self, ch_in, ch_out, max_pool=True):\n",
    "        layers = [nn.MaxPool2d(kernel_size=2)] if max_pool else []\n",
    "        layers += [\n",
    "            nn.Conv2d(ch_in, ch_out, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(ch_out, ch_out, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "        ]\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def get_last_block_inputs(self, x):\n",
    "        with torch.no_grad():\n",
    "            vars = self.forward_vars(x)\n",
    "\n",
    "            return vars['x1'], vars['u2']\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "root = \"small_data\"  # os.path.join(\"data\")\n",
    "device = \"cuda\"  # torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "transform = tv.transforms.Compose([\n",
    "    # tv.transforms.RandomAffine(0, translate=(5/96, 5/96), fill=(255,255,255)),\n",
    "    # tv.transforms.ColorJitter(hue=0.5),\n",
    "    tv.transforms.RandomHorizontalFlip(p=0.5),\n",
    "    tv.transforms.ToTensor(),\n",
    "    tv.transforms.Normalize((0.5, 0.5, 0.5,), (0.5, 0.5, 0.5,))\n",
    "])\n",
    "dataset = ImageFolder(\n",
    "    root=root,\n",
    "    transform=transform\n",
    ")\n",
    "dataloader = DataLoader(dataset,\n",
    "                        batch_size=16,\n",
    "                        shuffle=True,\n",
    "                        num_workers=1,\n",
    "                        drop_last=True\n",
    "                        )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([16, 3, 96, 96])"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = next(iter(dataloader))[0].to(device)\n",
    "img.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "down torch.Size([16, 8, 96, 96])\n",
      "down torch.Size([16, 16, 48, 48])\n",
      "down torch.Size([16, 32, 24, 24])\n",
      "down torch.Size([16, 64, 12, 12])\n",
      "up torch.Size([16, 64, 12, 12])\n",
      "up torch.Size([16, 32, 24, 24])\n",
      "up torch.Size([16, 16, 48, 48])\n",
      "up torch.Size([16, 8, 96, 96])\n"
     ]
    },
    {
     "data": {
      "text/plain": "torch.Size([16, 3, 96, 96])"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unet = Unet([8, 16, 32, 64, 128]).to(device)\n",
    "unet(img).shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class MyGeneratorUpsampling(nn.Module):\n",
    "    # input is (batch, latent_dim, 1, 1)\n",
    "    def __init__(self, latent_dim):\n",
    "        super().__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "        channels = [latent_dim, 64 * 8, 64 * 8, 64 * 4, 64 * 4, 64 * 2, 64, 64, 3]\n",
    "        params = [3, 2, 2, 2, 1, 2, 2, 1]\n",
    "        self.layers = nn.Sequential()\n",
    "        for i, (cur_channels, next_channels, scale) in enumerate(zip(channels[:-1], channels[1:], params)):\n",
    "            if scale > 1:\n",
    "                self.layers.append(nn.Upsample(scale_factor=scale))\n",
    "            self.layers.append(nn.Conv2d(cur_channels, next_channels, kernel_size=3, stride=1, padding=1))\n",
    "            self.layers.append(*[nn.Conv2d(next_channels, next_channels, kernel_size=3, padding=1),\n",
    "                                 nn.BatchNorm2d(next_channels)\n",
    "                                 nn.LeakyReLU(),\n",
    "                                 nn.Conv2d(next_channels, next_channels, kernel_size=3, padding=1),\n",
    "                                 nn.BatchNorm2d(next_channels),\n",
    "                                 nn.LeakyReLU()\n",
    "                                 ])\n",
    "\n",
    "            if i == len(params) - 1:\n",
    "                self.layers.append(nn.Tanh())\n",
    "            else:\n",
    "                self.layers.append(nn.BatchNorm2d(next_channels))\n",
    "                self.layers.append(nn.LeakyReLU())\n",
    "\n",
    "    def forward(self, x):\n",
    "        if len(x.shape) == 2:\n",
    "            x = x[:, :, None, None]\n",
    "\n",
    "        return self.layers(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}