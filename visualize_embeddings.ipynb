{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from main import Simplify\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision as tv\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "from aegan import AEGAN\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "LATENT_DIM = 32\n",
    "\n",
    "device = \"cpu\"  # torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "transform = tv.transforms.Compose([\n",
    "    tv.transforms.RandomAffine(0, translate=(5 / 96, 5 / 96), fill=(255, 255, 255)),\n",
    "    # tv.transforms.ColorJitter(hue=0.5),\n",
    "    tv.transforms.RandomHorizontalFlip(p=0.5),\n",
    "    # Simplify(),\n",
    "    tv.transforms.ToTensor(),\n",
    "    tv.transforms.Normalize((0.5, 0.5, 0.5,), (0.5, 0.5, 0.5,))\n",
    "])\n",
    "dataset = ImageFolder(\n",
    "    root=\"data_cleared\",\n",
    "    transform=transform\n",
    ")\n",
    "dataloader = DataLoader(dataset,\n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        shuffle=False,\n",
    "                        num_workers=1,\n",
    "                        drop_last=True\n",
    "                        )\n",
    "\n",
    "noise_fn = lambda x: torch.randn((x, LATENT_DIM), device=device)\n",
    "\n",
    "gan = AEGAN(\n",
    "    LATENT_DIM,\n",
    "    noise_fn,\n",
    "    dataloader,\n",
    "    device=device,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    channels_cnt=3,\n",
    "    colors_cnt=16,\n",
    "    is_old=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "gan.load(os.path.join(\"data_cleared_linear_upsampling_colorspace_stolen_discriminator_results\", \"checkpoints\"), 499)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# default `log_dir` is \"runs\" - we'll be more specific here\n",
    "writer = SummaryWriter('tensorboard')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "\n",
    "gan.encoder.eval()\n",
    "\n",
    "embeddings = []\n",
    "sprites = []\n",
    "metadata = []\n",
    "\n",
    "for filename in os.listdir(\"data_cleared/sprites_rgb\"):\n",
    "    img = Image.open(Path() / \"data_cleared/sprites_rgb\" / filename)\n",
    "    # as_array = np.array(img)\n",
    "    as_tensor = tv.transforms.ToTensor()(img)[None, :, :, :]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        embedding = gan.encoder(as_tensor)\n",
    "\n",
    "    img.thumbnail([28, 28], Image.ANTIALIAS)\n",
    "    embeddings.append(embedding[0])\n",
    "    sprites.append(tv.transforms.ToTensor()(img))\n",
    "    metadata.append(filename)\n",
    "    # break\n",
    "\n",
    "writer.add_embedding(torch.stack(embeddings), label_img=torch.stack(sprites), metadata=metadata)\n",
    "writer.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n"
     ]
    }
   ],
   "source": [
    "writer.add_embedding(torch.stack(embeddings), label_img=torch.stack(sprites), metadata=torch.Tensor(range(len(embeddings))))\n",
    "writer.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'thumbnail'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Input \u001B[1;32mIn [15]\u001B[0m, in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mimg\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mthumbnail\u001B[49m([\u001B[38;5;241m96\u001B[39m, \u001B[38;5;241m96\u001B[39m], Image\u001B[38;5;241m.\u001B[39mANTIALIAS)\n\u001B[0;32m      2\u001B[0m np\u001B[38;5;241m.\u001B[39marray(img)\u001B[38;5;241m.\u001B[39mshape\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'NoneType' object has no attribute 'thumbnail'"
     ]
    }
   ],
   "source": [
    "img.thumbnail([96, 96], Image.ANTIALIAS)\n",
    "np.array(img).shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}